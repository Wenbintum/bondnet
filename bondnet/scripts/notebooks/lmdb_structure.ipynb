{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santiagovargas/anaconda3/envs/bondnet/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import numpy as np\n",
    "import lmdb\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from torch.utils.data import random_split\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import pickle5 as pickle\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "import dgl\n",
    "from dgl import heterograph\n",
    "from dgl import DGLGraph\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "from bondnet.data.reaction_network import ReactionNetworkLMDB\n",
    "from bondnet.data.utils import construct_rxn_graph_empty, create_rxn_graph\n",
    "from bondnet.model.training_utils import load_model_lightning\n",
    "from bondnet.test_utils import get_defaults\n",
    "from bondnet.data.dataset import ReactionNetworkLMDBDataset\n",
    "from bondnet.data.dataloader import DataLoaderReactionNetworkLMDB, collate_parallel_lmdb\n",
    "\n",
    "class LmdbBaseDataset(Dataset):\n",
    "\n",
    "    \"\"\"\n",
    "    Dataset class to\n",
    "    1. write Reaction networks objecs to lmdb\n",
    "    2. load lmdb files\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config, transform=None):\n",
    "        super(LmdbBaseDataset, self).__init__()\n",
    "\n",
    "        self.config = config\n",
    "        self.path = Path(self.config[\"src\"])\n",
    "\n",
    "        # Get metadata in case\n",
    "        # self.metadata_path = self.path.parent / \"metadata.npz\"\n",
    "        self.env = self.connect_db(self.path)\n",
    "\n",
    "        # If \"length\" encoded as ascii is present, use that\n",
    "        # If there are additional properties, there must be length.\n",
    "        length_entry = self.env.begin().get(\"length\".encode(\"ascii\"))\n",
    "        if length_entry is not None:\n",
    "            num_entries = pickle.loads(length_entry)\n",
    "        else:\n",
    "            # Get the number of stores data from the number of entries\n",
    "            # in the LMDB\n",
    "            num_entries = self.env.stat()[\"entries\"]\n",
    "\n",
    "        self._keys = list(range(num_entries))\n",
    "        self.num_samples = num_entries\n",
    "\n",
    "        # Get portion of total dataset\n",
    "        self.sharded = False\n",
    "        if \"shard\" in self.config and \"total_shards\" in self.config:\n",
    "            self.sharded = True\n",
    "            self.indices = range(self.num_samples)\n",
    "            # split all available indices into 'total_shards' bins\n",
    "            self.shards = np.array_split(\n",
    "                self.indices, self.config.get(\"total_shards\", 1)\n",
    "            )\n",
    "            # limit each process to see a subset of data based off defined shard\n",
    "            self.available_indices = self.shards[self.config.get(\"shard\", 0)]\n",
    "            self.num_samples = len(self.available_indices)\n",
    "\n",
    "        # TODO\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # if sharding, remap idx to appropriate idx of the sharded set\n",
    "        if self.sharded:\n",
    "            idx = self.available_indices[idx]\n",
    "\n",
    "        #!CHECK, _keys should be less then total numbers of keys as there are more properties.\n",
    "        datapoint_pickled = self.env.begin().get(f\"{self._keys[idx]}\".encode(\"ascii\"))\n",
    "\n",
    "        data_object = pickle.loads(datapoint_pickled)\n",
    "\n",
    "        # TODO\n",
    "        if self.transform is not None:\n",
    "            data_object = self.transform(data_object)\n",
    "\n",
    "        return data_object\n",
    "\n",
    "    def connect_db(self, lmdb_path=None):\n",
    "        env = lmdb.open(\n",
    "            str(lmdb_path),\n",
    "            subdir=False,\n",
    "            readonly=False,\n",
    "            lock=False,\n",
    "            readahead=True,\n",
    "            meminit=False,\n",
    "            max_readers=1,\n",
    "        )\n",
    "        return env\n",
    "\n",
    "    def close_db(self):\n",
    "        if not self.path.is_file():\n",
    "            for env in self.envs:\n",
    "                env.close()\n",
    "        else:\n",
    "            self.env.close()\n",
    "\n",
    "    def get_metadata(self, num_samples=100):\n",
    "        pass\n",
    "\n",
    "class LmdbMoleculeDataset(LmdbBaseDataset):\n",
    "    def __init__(self, config, transform=None):\n",
    "        super(LmdbMoleculeDataset, self).__init__(config=config, transform=transform)\n",
    "\n",
    "    @property\n",
    "    def charges(self):\n",
    "        charges = self.env.begin().get(\"charges\".encode(\"ascii\"))\n",
    "        return pickle.loads(charges)\n",
    "\n",
    "    @property\n",
    "    def ring_sizes(self):\n",
    "        ring_sizes = self.env.begin().get(\"ring_sizes\".encode(\"ascii\"))\n",
    "        return pickle.loads(ring_sizes)\n",
    "\n",
    "    @property\n",
    "    def elements(self):\n",
    "        elements = self.env.begin().get(\"elements\".encode(\"ascii\"))\n",
    "        return pickle.loads(elements)\n",
    "\n",
    "    @property\n",
    "    def feature_info(self):\n",
    "        feature_info = self.env.begin().get(\"feature_info\".encode(\"ascii\"))\n",
    "        return pickle.loads(feature_info)\n",
    "\n",
    "class LmdbReactionDataset(LmdbBaseDataset):\n",
    "    def __init__(self, config, transform=None):\n",
    "        super(LmdbReactionDataset, self).__init__(config=config, transform=transform)\n",
    "\n",
    "    @property\n",
    "    def dtype(self):\n",
    "        dtype = self.env.begin().get(\"dtype\".encode(\"ascii\"))\n",
    "        return  pickle.loads(dtype)\n",
    "            \n",
    "    @property\n",
    "    def feature_size(self):\n",
    "        feature_size = self.env.begin().get(\"feature_size\".encode(\"ascii\"))\n",
    "        return pickle.loads(feature_size)\n",
    "\n",
    "    @property\n",
    "    def feature_name(self):\n",
    "        feature_name = self.env.begin().get(\"feature_name\".encode(\"ascii\"))\n",
    "        return pickle.loads(feature_name)\n",
    "    \n",
    "    @property\n",
    "    def mean(self):\n",
    "        mean = self.env.begin().get(\"mean\".encode(\"ascii\"))\n",
    "        return pickle.loads(mean)\n",
    "    \n",
    "    @property\n",
    "    def std(self):\n",
    "        std = self.env.begin().get(\"std\".encode(\"ascii\"))\n",
    "        return pickle.loads(std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, -1, -2} {6} {'H', 'F', 'O', 'S', 'C'} {}\n",
      "2340\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"src\": \"/home/santiagovargas/dev/bondnet/bondnet/dataset/lmdb_dev/mol.lmdb\"\n",
    "}\n",
    "mol = LmdbMoleculeDataset(config=config)\n",
    "\n",
    "print(\n",
    "    mol.charges, \n",
    "    mol.ring_sizes, \n",
    "    mol.elements, \n",
    "    mol.feature_info\n",
    ")\n",
    "\n",
    "config = {\n",
    "    \"src\": \"/home/santiagovargas/dev/bondnet/bondnet/dataset/lmdb_dev/reaction.lmdb\"\n",
    "}\n",
    "reaction = LmdbReactionDataset(config=config)\n",
    "print(len(reaction))\n",
    "\n",
    "rxn_ntwk = ReactionNetworkLMDB(mol, reaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'atom': 13, 'bond': 7, 'global': 8}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reaction.feature_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test = rxn_ntwk.subselect_reactions([4])[0][0]\n",
    "test[\"reaction_molecule_info\"][\"reactants\"][\"reactants\"] = [0]\n",
    "test[0] = 1\n",
    "test_copy = deepcopy(test)\n",
    "test_copy[0] = 1\n",
    "print(test[\"reaction_molecule_info\"][\"reactants\"][\"reactants\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ReactionNetworkLMDBDataset(rxn_ntwk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoaderReactionNetworkLMDB(\n",
    "    dataset, batch_size=100, shuffle=True, collate_fn=collate_parallel_lmdb\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['reactants', 'atom_map', 'bond_map', 'init_reactants'])\n"
     ]
    }
   ],
   "source": [
    "sample = next(iter(dataloader))\n",
    "print((sample[1][\"reaction\"][0][\"reaction_molecule_info\"][\"reactants\"].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB: using GatedGCNConv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "config = get_defaults()\n",
    "\n",
    "config = {\n",
    "    \"model\": {\n",
    "        \"extra_features\": [],\n",
    "        \"extra_info\": [],\n",
    "        \"debug\": False,\n",
    "        \"classifier\": False,\n",
    "        \"classif_categories\": 3,\n",
    "        \"filter_species\": [3, 6],\n",
    "        \"filter_outliers\": False,\n",
    "        \"filter_sparse_rxns\": False,\n",
    "        \"restore\": False,\n",
    "    },\n",
    "    \"optim\": {\n",
    "        \"val_size\": 0.1,\n",
    "        \"test_size\": 0.1,\n",
    "        \"batch_size\": 4,\n",
    "        \"num_workers\": 1,\n",
    "    },\n",
    "}\n",
    "\n",
    "dataset_loc = \"../../../tests/data/testdata/barrier_100.json\"\n",
    "config = {\n",
    "    \"dataset\": {\n",
    "        \"data_dir\": dataset_loc,\n",
    "        \"target_var\": \"ts\",\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"extra_features\": [],\n",
    "        \"extra_info\": [],\n",
    "        \"debug\": False,\n",
    "        \"classifier\": False,\n",
    "        \"classif_categories\": 3,\n",
    "        \"filter_species\": [3, 6],\n",
    "        \"filter_outliers\": False,\n",
    "        \"filter_sparse_rxns\": False,\n",
    "        \"restore\": False,\n",
    "    },\n",
    "    \"optim\": {\n",
    "        \"val_size\": 0.2,\n",
    "        \"test_size\": 0.2,\n",
    "        \"batch_size\": 4,\n",
    "        \"num_workers\": 1,\n",
    "    },\n",
    "}\n",
    "config_model = get_defaults()\n",
    "# update config with model settings\n",
    "for key, value in config_model[\"model\"].items():\n",
    "    config[\"model\"][key] = value\n",
    "for key, value in config_model[\"model\"].items():\n",
    "    config[\"model\"][key] = value\n",
    "    \n",
    "#from bondnet.data.datamodule import BondNetLightningDataModule\n",
    "#dm = BondNetLightningDataModule(config)\n",
    "# feat_size, feat_name = dm.prepare_data()\n",
    "# config[\"model\"][\"in_feats\"] = feat_size\n",
    "# config[\"model\"][\"in_feats\"] = feat_size\n",
    "# config = get_defaults()\n",
    "#config[\"model\"][\"in_feats\"] = dataset.feature_info[\"feature_size\"]\n",
    "\n",
    "config[\"model\"][\"in_feats\"] = reaction.feature_size\n",
    "model = load_model_lightning(config[\"model\"], load_dir=\"./test_lmdb/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_887645/4045836837.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mbatched_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"ft\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mft\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mgraphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mreaction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m#print(reaction[0][\"mappings\"])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/dgl/batch.py\u001b[0m in \u001b[0;36munbatch\u001b[0;34m(g, node_split, edge_split)\u001b[0m\n\u001b[1;32m    424\u001b[0m     gs = [\n\u001b[1;32m    425\u001b[0m         \u001b[0mconvert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheterograph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_nodes_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0medge_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_nodes_dict\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_dict_per\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_nodes_dict_per\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m     ]\n\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/dgl/batch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    424\u001b[0m     gs = [\n\u001b[1;32m    425\u001b[0m         \u001b[0mconvert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheterograph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_nodes_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0medge_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_nodes_dict\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_dict_per\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_nodes_dict_per\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m     ]\n\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/dgl/convert.py\u001b[0m in \u001b[0;36mheterograph\u001b[0;34m(data_dict, num_nodes_dict, idtype, device)\u001b[0m\n\u001b[1;32m    373\u001b[0m             \u001b[0mdsttype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mnum_nodes_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msrctype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m             \u001b[0mnum_nodes_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdsttype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m         )\n\u001b[1;32m    377\u001b[0m         \u001b[0mrel_graphs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/dgl/convert.py\u001b[0m in \u001b[0;36mcreate_from_edges\u001b[0;34m(sparse_fmt, arrays, utype, etype, vtype, urange, vrange, row_sorted, col_sorted)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDGLGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhgidx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mutype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDGLGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhgidx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mutype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/dgl/heterograph.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, gidx, ntypes, etypes, node_frames, edge_frames, **deprecate_kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0;34m\" removed in all cases.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeprecate_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             )\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgidx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_frames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgidx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_frames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/dgl/heterograph.py\u001b[0m in \u001b[0;36m_init\u001b[0;34m(self, gidx, ntypes, etypes, node_frames, edge_frames)\u001b[0m\n\u001b[1;32m    198\u001b[0m         node_frames = [\n\u001b[1;32m    199\u001b[0m             \u001b[0mFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_rows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         ]\n\u001b[1;32m    202\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode_frames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/dgl/heterograph.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    198\u001b[0m         node_frames = [\n\u001b[1;32m    199\u001b[0m             \u001b[0mFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_rows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         ]\n\u001b[1;32m    202\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode_frames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "nodes = [\"atom\", \"bond\", \"global\"]\n",
    "for it, (batched_graph, label) in enumerate(dataloader):\n",
    "    feats = {nt: batched_graph.nodes[nt].data[\"feat\"] for nt in nodes}\n",
    "    target = label[\"value\"].view(-1).to(device)\n",
    "    norm_atom = None\n",
    "    norm_bond = None\n",
    "    stdev = torch.tensor([1.0])\n",
    "    # print(feats.keys())\n",
    "    # if device is not None:\n",
    "    # feats = {k: v.to(device) for k, v in feats.items()}\n",
    "    # target = target.to(device)\n",
    "    # norm_atom = norm_atom.to(device)\n",
    "    # norm_bond = norm_bond.to(device)\n",
    "    # stdev = stdev.to(device)\n",
    "\n",
    "    # print(label[\"reaction\"][0][\"reaction_molecule_info\"][\"mappings\"].keys())\n",
    "    # print(label[\"reaction\"][0][\"reaction_molecule_info\"][\"mappings\"][\"num_bonds_total\"])\n",
    "    # print(label[\"reaction\"][0][\"reaction_molecule_info\"][\"mappings\"][\"num_atoms_total\"])\n",
    "    \n",
    "    reactions = label[\"reaction\"]\n",
    "    for nt, ft in feats.items():\n",
    "        batched_graph.nodes[nt].data.update({\"ft\": ft})\n",
    "\n",
    "    graphs = dgl.unbatch(batched_graph)\n",
    "    reaction[0]\n",
    "    #print(reaction[0][\"mappings\"])\n",
    "    model(\n",
    "        graph=batched_graph,\n",
    "        feats=feats,\n",
    "        reactions=reactions,\n",
    "        norm_atom=norm_atom,\n",
    "        norm_bond=norm_bond,\n",
    "        reverse=False,\n",
    "    )\n",
    "\n",
    "    for rxn in reactions:\n",
    "        reactants = [\n",
    "            graphs[i] for i in rxn[\"reaction_molecule_info\"][\"reactants\"][\"reactants\"]\n",
    "        ]\n",
    "        products = [\n",
    "            graphs[i] for i in rxn[\"reaction_molecule_info\"][\"products\"][\"products\"]\n",
    "        ]\n",
    "        # print(rxn[\"reaction_molecule_info\"][\"products\"][\"products\"])\n",
    "        # print(len(products))\n",
    "\n",
    "        \n",
    "        mappings = rxn[\"mappings\"]\n",
    "        #print(mappings)\n",
    "        has_bonds = rxn[\"has_bonds\"]\n",
    "        \n",
    "        \n",
    "        #reactant_atom_map = rxn[\"reaction_molecule_info\"][\"reactants\"][\"atom_map\"]\n",
    "        #product_atom_map = rxn[\"reaction_molecule_info\"][\"products\"][\"atom_map\"]\n",
    "        #reactant_bond_map = rxn[\"reaction_molecule_info\"][\"reactants\"][\"bond_map\"]\n",
    "        #product_bond_map = rxn[\"reaction_molecule_info\"][\"products\"][\"bond_map\"]\n",
    "        \n",
    "\n",
    "        #mappings = {\"bond_map\": None, \"atom_map\": None}\n",
    "        #has_bonds = False\n",
    "        g, fts = create_rxn_graph(\n",
    "            reactants=reactants,\n",
    "            products=products,\n",
    "            mappings=mappings,\n",
    "            device=device,\n",
    "            has_bonds=has_bonds,\n",
    "            reverse=False,\n",
    "            reactant_only=False,\n",
    "            empty_graph_fts=None,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name            | Type              | Params\n",
      "-------------------------------------------------------\n",
      "0  | embedding       | UnifySize         | 672   \n",
      "1  | gated_layers    | ModuleList        | 3.0 M \n",
      "2  | readout_layer   | Set2SetThenCat    | 6.3 M \n",
      "3  | fc_layers       | ModuleList        | 656 K \n",
      "4  | loss            | MeanSquaredError  | 0     \n",
      "5  | train_r2        | R2Score           | 0     \n",
      "6  | train_torch_l1  | MeanAbsoluteError | 0     \n",
      "7  | train_torch_mse | MeanSquaredError  | 0     \n",
      "8  | val_r2          | R2Score           | 0     \n",
      "9  | val_torch_l1    | MeanAbsoluteError | 0     \n",
      "10 | val_torch_mse   | MeanSquaredError  | 0     \n",
      "11 | test_r2         | R2Score           | 0     \n",
      "12 | test_torch_l1   | MeanAbsoluteError | 0     \n",
      "13 | test_torch_mse  | MeanSquaredError  | 0     \n",
      "-------------------------------------------------------\n",
      "9.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "9.9 M     Total params\n",
      "39.742    Total estimated model params size (MB)\n",
      "/home/santiagovargas/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:1613: PossibleUserWarning: The number of training batches (24) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  66%|██████▋   | 389/585 [00:38<00:19, 10.19it/s, loss=4.78, v_num=6]\n",
      "Epoch 0: 100%|██████████| 24/24 [00:16<00:00,  1.44it/s, loss=3.11, v_num=7, train_loss=3.300]"
     ]
    },
    {
     "ename": "MisconfigurationException",
     "evalue": "ReduceLROnPlateau conditioned on metric val_loss which is not available. Available metrics are: ['train_loss', 'train_r2', 'train_l1', 'train_mse']. Condition can be set using `monitor` key in lr scheduler dict",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_887645/1373636847.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lightning_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         call._call_and_handle_interrupt(\n\u001b[0;32m--> 609\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    610\u001b[0m         )\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_TunerExitException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    648\u001b[0m             \u001b[0mmodel_connected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m         )\n\u001b[0;32m--> 650\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkpoint_connector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.__class__.__name__}: trainer tearing down\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pre_training_routine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detect_anomaly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1214\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0m_EVALUATE_OUTPUT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/loops/loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restarting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/loops/fit_loop.py\u001b[0m in \u001b[0;36mon_advance_end\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0;31m# since metric-based schedulers require access to metrics and those are not currently saved in the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0;31m# checkpoint, the plateau schedulers shouldn't be updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_lr_schedulers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_plateau_schedulers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestarting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;31m# we manually decrease here because loggers expect that the same step is used when logging epoch-end metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\u001b[0m in \u001b[0;36mupdate_lr_schedulers\u001b[0;34m(self, interval, update_plateau_schedulers)\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0minterval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0mupdate_plateau_schedulers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdate_plateau_schedulers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m             \u001b[0mopt_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mopt_idx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactive_optimizers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m         )\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\u001b[0m in \u001b[0;36m_update_learning_rates\u001b[0;34m(self, interval, update_plateau_schedulers, opt_indices)\u001b[0m\n\u001b[1;32m    439\u001b[0m                             \u001b[0mavail_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m                             raise MisconfigurationException(\n\u001b[0;32m--> 441\u001b[0;31m                                 \u001b[0;34mf\"ReduceLROnPlateau conditioned on metric {monitor_key}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m                                 \u001b[0;34mf\" which is not available. Available metrics are: {avail_metrics}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                                 \u001b[0;34m\" Condition can be set using `monitor` key in lr scheduler dict\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMisconfigurationException\u001b[0m: ReduceLROnPlateau conditioned on metric val_loss which is not available. Available metrics are: ['train_loss', 'train_r2', 'train_l1', 'train_mse']. Condition can be set using `monitor` key in lr scheduler dict"
     ]
    }
   ],
   "source": [
    "project_name = \"test_multi_gpu\"\n",
    "\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=2,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=[0],\n",
    "    accumulate_grad_batches=5,\n",
    "    enable_progress_bar=True,\n",
    "    gradient_clip_val=1.0,\n",
    "    enable_checkpointing=True,\n",
    "    precision=32,\n",
    ")\n",
    "\n",
    "trainer.fit(model, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bondnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
